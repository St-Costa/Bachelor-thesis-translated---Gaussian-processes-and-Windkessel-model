\chapter{Conclusioni e future directions}
In questo capitolo vengono riepilogati i principali risultati ottenuti nel corso dell'elaborato e vengono proposte delle \textit{future directions} che potrebbero migliorare quanto studiato in termini sia teorici che pratici.

\begin{textblock*}{0.64\textwidth}(3.5cm+0.36\textwidth,18.5cm)
\epigraph{A conclusion is the place where you get tired of thinking.}{Arthur Bloch}
\end{textblock*}

\newpage



\section{Conclusioni}
Si è visto nel corso dell'elaborato cosa siano i processi gaussiani e, in particolare, si è spiegato in che senso generalizzano la distribuzione gaussiana multivariata. Sono state illustrate le principali kernel function, spiegando il significato dei parametri delle funzioni (chiamati in fase di apprendimento supervisionato \textit{iperparametri}). Si è poi spiegato come generalizzare le covariance functions in più dimensioni, per poi applicare questa generalizzazione al contesto dell'apprendimento supervisionato.

Quindi si è spiegato come utilizzare i processi gaussiani per la predizione di osservazioni senza rumore (o interpolazione) e con rumore (osservazioni \textit{noisy}), mostrando quanto sia semplice in termini teorici ottenere risultati notevoli.\\

Nonostante quanto visto, cioè la semplicità e la potenza dei processi gaussiani, vale la pena spiegare perchè non siano molto usati nel panorama scientifico: solo recentemente, infatti, ci sono alcuni gruppi di ricerca che li applicano a contesti emodinamici, come ad esempio \cite{doi:10.1098/rsta.2019.0334} e \cite{Yuhn2022.03.10.483573}. I principali motivi che \cite{rasmussen_gaussian_2006} identifica per motivare il basso interesse scientifico sono due: il primo è che l'applicazione dei processi gaussiani richiede la gestione di grandi matrici e in particolare l'inversione di esse, cosa diventata affrontabile computazionalmente solo negli ultimi decenni; il secondo è che la maggior parte dello studio teorico è stato fatto utilizzando le stesse funzioni di covarianza, con poca consapevolezza a riguardo e quindi senza sfruttare la potenza di questa tecnologia. Ricerche come \cite{duvenaud_automatic_2014} e libri come \cite{rasmussen_gaussian_2006} hanno sicuramente aiutato la comunità scientifica in questo senso. \\

Si è poi introdotto nell'elaborato il modello Windkessel lasciando ampio spazio alla parte applicativa. Nonostante il modello sia piuttosto semplice, essendo formato solo da una equazione differenziale, fornisce risultati di una precisione notevole. All'interno dello stesso capitolo è stata studiata la sensitività locale delle variabili rispetto ai parametri, che ha permesso di comprendere quanto poco la pressione distale $P_d$ abbia influenza su MAP, DBP, SBP, PP; per questo motivo è stata scartata dai parametri dell'apprendimento supervisionato perché, lasciandola, si rischiava di peggiorare le prestazioni del modello statistico sia in termini di tempo di apprendimento che in termini di precisione.\\

Infine sono stati riportati i risultati di apprendimento supervisionato eseguito con la libreria GPErks dopo aver spiegato il suo funzionamento dal punto di vista statistico. Questi risultati permettono di concludere che effettivamente i processi gaussiani forniscono una scorciatoia all'approssimazione di MAP, DBP, SBP e PP rispetto all'uso del modello Windkessel. Con i giusti parametri, si è visto che l'apprendimento supervisionato fornisce una deviazione standard, dunque un errore, accettabile\footnote{Il termine \textit{accettabile} si riferisce alla precisione che si può accettare in un contesto clinico dove gli errori di misurazione dei parametri fisiologici possono essere molto alti.} con un training abbastanza breve. Inoltre, a partire dai parametri di input del modello Windkessel, il processo gaussiano addestrato è in grado di restituire il valore di MAP, SBP, DBP e PP molto più velocemente e con minore costo computazionale rispetto all'uso del modello Windkessel, quindi alla risoluzione di un'equazione differenziale fino a convergenza. Per questi motivi i processi gaussiani si sono dimostrati uno strumento con alte potenzialità e con ampi usi nella matematica applicata.



\section{Future directions}
Lo studio approfondito e sistematico dei processi gaussiani, della base teorica bayesiana su cui poggia l'apprendimento supervisionato e del modello Windkessel consentono di identificare con facilità, a posteriori, come è possibile migliorare l'approccio usato.\\

Ad esempio, nell'elaborato è stato usato il squared-exponential kernel e una linear mean function. Ai fini di quanto studiato hanno funzionato perfettamente, ma la scelta della kernel function e della mean function merita di essere fatta con la giusta attenzione. Come visto in \ref{section: mauna loa}, la scelta di covariance function composte può richiedere un lungo studio a partire dalla conoscenza (che quindi deve essere approfondita) dell'evento che si vuole modellare ottenendo, però, un notevole aumento di precisione in fase di training.

L'early stopper dovrebbe essere studiato approfonditamente ed eventualmente modificato\footnote{Gli early stopper non seguono delle regole precise, ci sono delle ricerce scientifiche che ne suggeriscono la forma e forniscono esempi di implementazione. Ottimale sarebbe costruirli specificamente per ogni problema, ma la cosa può richiedere molto tempo.} in base al problema specifico per evitare al meglio l'overfitting e imporre con precisione il numero di EPOCHS e quindi il tempo di esecuzione richiesto alla fase di training. In contesti clinici, ad esempio, può essere preferibile un tempo di esecuzione basso a discapito di una precisione minore per offrire al medico un supporto in tempo reale. Si noti infatti che nei contesti clinici è inutile richiedere un'alta precisione ai risultati di training perché le misurazioni dei pazienti possono essere soggette a notevoli errori di misurazione.

La scelta del metodo di ottimizzazione deve essere fatta in base al problema che si sta affrontando. Ogni metodo, infatti, ha vantaggi e svantaggi che devono essere studiati con attenzione per poter ottimizzare il training. Inoltre, in base al metodo, è necessario studiare approfonditamente anche i parametri impostabili, ad esempio il learning rate, che possono modificare la velocità del training e le sue prestazioni.


Un'altra miglioria che si può apportare al training è quello di utilizzare dei dati reali per verificare il modello, permettendo di avere un feedback più affidabile sul suo funzionamento. Ci sono diversi modi per farlo, un modo semplice è quello di utilizzare un validation set di dati reali, in modo che in fase di training il modello, dopo ogni fase di addestramento sul training set, validi il suo funzionamento su dati reali. Questo miglioria non è sempre apportabile, poiché talvolta non ci sono dataset reali dei valori che interessano il training. Ad esempio per il problema affrontato nell'elaborato non si trovava un database di dati reali adeguato: l'unica possibilità era utilizzare un database generato da un modello più complesso del modello Windkessel.

Un approccio al training che diminuirebbe notevolmente il rischio di overfitting è il $K$-fold cross validation. Questa tecnica consiste nel dividere il dataset intero in $k$ sottocampioni di uguale dimensione. Viene eseguito il training $k$ volte dove ogni volta viene usato uno dei $k$ sottocampioni come validation test e gli altri $k-1$ come training set\footnote{Eventualmente è possibile usare uno dei $k-1$ sottocampioni come testing set. In realtà ci sono diverse forme di $k$-fold cross validation e differiscono per l'uso dei $k$ sottocampioni; l'idea di base è eseguire più test partizionando il dataset.}. Si ottengono quindi $k$ risultati che vengono mediati per generare una singola stima. Cambiare il validation set e il training set ad ogni training abbassa la probabilità di incorrere in overfitting.

In un contesto come quello visto nell'elaborato, la sensitività locale è stata sufficiente per escludere $P_d$ dai parametri da tenere in considerazione poiché ha dimostrato influire poco nei valori di MAP, DBP, SBP, PP (bassa influenza confermata anche dai risultati di training). In situazioni molto più grandi, con molti più parametri in input (un problema reale può arrivare a centinaia e potenzialmente anche migliaia di parametri), un'analisi più approfondita e non locale è quella della global sensitivity analysis, che permette di capire, in modo globale, quali sono i parametri che influenzano gli output. Ciò può comportare una diminuzione notevole del numero di parametri da considerare, velocizzando il training e aumentandone le performance.

Poiché per ogni variabile MAP, DBP, SBP, PP viene fatto un training indipendente, a partire dagli stessi parametri di input si ottengono delle approssimazioni di MAP, DBP, SBP e PP che non sono correlate tra loro, nel senso che, probabilmente, si avrà $\text{PP}\neq \text{SBP} - \text{DBP}$. Generalmente ciò non è un problema particolarmente grave, ricordando, come detto in precedenza, che in situazioni cliniche si hanno grandi errori di misurazione. Tuttavia un training contemporaneo di tutte le variabili eviterebbe problematiche simili, seppur si tratta di una tecnica di training piuttosto complicata.