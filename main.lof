\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {II.1}{\ignorespaces Funzione di ripartizione e densità di probabilità di una distribuzione normale standard \blx@tocontentsinit {0}\cite {wikiNormalDistribution}.\relax }}{8}{figure.caption.7}%
\contentsline {figure}{\numberline {II.2}{\ignorespaces Nube di punti generata da una distribuzione gaussiana bivariata con componenti incorrelate \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{11}{figure.caption.8}%
\contentsline {figure}{\numberline {II.3}{\ignorespaces Nube di punti generata da una distribuzione gaussiana bivariata con componenti correlate \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{12}{figure.caption.9}%
\contentsline {figure}{\numberline {II.4}{\ignorespaces Nube di punti generata da una distribuzione gaussiana bivariata con componenti fortemente correlate \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{13}{figure.caption.10}%
\contentsline {figure}{\numberline {II.5}{\ignorespaces Due diversi approcci visivi alla correlazione di componenti di vettori gaussiani multivariati: $n=2$ \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{14}{figure.caption.11}%
\contentsline {figure}{\numberline {II.6}{\ignorespaces Visualizzazione tramite segmenti della correlazione di componenti di vettori gaussiani multivariati: $n=5$ \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{15}{figure.caption.12}%
\contentsline {figure}{\numberline {II.7}{\ignorespaces Debole e forte correlazione delle componenti di vettori gaussiani multivariati visualizzata tramite segmenti \blx@tocontentsinit {0}\cite {damianou_gaussian_2016}.\relax }}{16}{figure.caption.13}%
\contentsline {figure}{\numberline {II.8}{\ignorespaces Visualizzazione tramite segmenti della correlazione di componenti di vettori gaussiani multivariati: $n=50$ \blx@tocontentsinit {0}\cite {wilkinson_introduction_2020}.\relax }}{16}{figure.caption.14}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {III.1}{\ignorespaces Regressione nonlineare \blx@tocontentsinit {0}\cite {turner_gaussian_2016}.\relax }}{18}{figure.caption.15}%
\contentsline {figure}{\numberline {III.2}{\ignorespaces Regressione nonlineare con processi gaussiani \blx@tocontentsinit {0}\cite {turner_gaussian_2016}.\relax }}{19}{figure.caption.16}%
\contentsline {figure}{\numberline {III.3}{\ignorespaces Quattro vettori generati da un processo gaussiano definito come nell'esempio \ref {esempioProcessoGaussiano}. Codice \ref {Example}.\relax }}{23}{figure.caption.17}%
\contentsline {figure}{\numberline {III.4}{\ignorespaces Grafico di $k(x,x')$ linear kernel, $\sigma _b^2=1$, $\sigma _v^2=1$, $c=-1$ e $x'=1$. Codice \ref {linear kernel code}\relax }}{25}{figure.caption.18}%
\contentsline {figure}{\numberline {III.5}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il linear kernel e $\sigma _b^2=0$, $\sigma _v^2=1$, $c=0$. Codice \ref {linear sample}.\relax }}{26}{figure.caption.19}%
\contentsline {figure}{\numberline {III.6}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il linear kernel e $\sigma _b^2=0$, $\sigma _v^2=1$, il parametro $c$ viene variato. Codice \ref {Linear - c}.\relax }}{27}{figure.caption.20}%
\contentsline {figure}{\numberline {III.7}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il linear kernel e $\sigma _v^2=1$, $c=0$, il parametro $\sigma _b^2$ viene variato. Codice \ref {Linear - sigmab}.\relax }}{27}{figure.caption.21}%
\contentsline {figure}{\numberline {III.8}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il linear kernel e $\sigma _b^2=0$, $c=0$, il parametro $\sigma _v^2$ viene variato. Codice \ref {Linear - sigmav}.\relax }}{28}{figure.caption.22}%
\contentsline {figure}{\numberline {III.9}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(m,k)$ dove $m(x)=x^3$ e $k(x,x')$ è il linear kernel, $\sigma _b^2=1$, $\sigma _v^2=10$, $c=0$. Codice \ref {linear cubedmean}.\relax }}{28}{figure.caption.23}%
\contentsline {figure}{\numberline {III.10}{\ignorespaces Grafico di $k(x,x')$ squared-exponential kernel, $\sigma ^2=1$ e $l^2=1$. Codice \ref {squared-exponential}.\relax }}{29}{figure.caption.24}%
\contentsline {figure}{\numberline {III.11}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è lo squared-exponential kernel e $l^2=1$, $\sigma ^2=1$. Codice \ref {RBF sample}.\relax }}{30}{figure.caption.25}%
\contentsline {figure}{\numberline {III.12}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è lo squared-exponential kernel e $l^2=1$, il parametro $\sigma ^2$ viene variato. Codice \ref {RBF - sigma}.\relax }}{31}{figure.caption.26}%
\contentsline {figure}{\numberline {III.13}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è lo squared-exponential kernel e $\sigma ^2=1$, il parametro $l^2$ viene variato. Codice \ref {codice9}.\relax }}{31}{figure.caption.27}%
\contentsline {figure}{\numberline {III.14}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(m,k)$ dove $m(x)=x^3$ e $k(x,x')$ lo squared-exponential kernel, $\sigma ^2=7$ e $l=0.3$. Codice \ref {codice10}.\relax }}{32}{figure.caption.28}%
\contentsline {figure}{\numberline {III.15}{\ignorespaces Grafico di $k(x,x')$ periodic kernel, $\sigma ^2=1$, $l^2=1$, $p=2$. Codice \ref {periodic Kernel}.\relax }}{33}{figure.caption.29}%
\contentsline {figure}{\numberline {III.16}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il periodic kernel e $\sigma ^2=1$, $l^2=2$, $p=1$. Codice \ref {periodic sample}.\relax }}{34}{figure.caption.30}%
\contentsline {figure}{\numberline {III.17}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il periodic kernel e $l^2=1, p=1$, il parametro $\sigma ^2$ viene variato. Codice \ref {Periodic sigma}.\relax }}{34}{figure.caption.31}%
\contentsline {figure}{\numberline {III.18}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il periodic kernel e $\sigma ^2=1$, $l^2=1$ e il parametro $p$ viene variato. Codice \ref {periodic p}.\relax }}{35}{figure.caption.32}%
\contentsline {figure}{\numberline {III.19}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il periodic kernel e $\sigma ^2=1$, $p=1$ e il parametro $l^2$ viene variato. Codice \ref {periodic l}.\relax }}{35}{figure.caption.33}%
\contentsline {figure}{\numberline {III.20}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(m,k)$ dove $m(x)=x^3$ e $k(x,x')$ il periodic kernel, $\sigma ^2=8$, $l^2=1$ e $p=0.5$. Codice \ref {priodic cubedmean}.\relax }}{36}{figure.caption.34}%
\contentsline {figure}{\numberline {III.21}{\ignorespaces Grafico di funzione con distribuzione $f\sim \mathcal {GP}(0,k)$ con $k(x,x')$ lo squared-exponential kernel in due dimensioni in cui $M=\text {diag}(1,3)^{-2}$. La funzione tende a cambiare più velocemente lungo la direzione $x_1$ che lungo la direzione $x_2$. \blx@tocontentsinit {0}\cite {murphy_machine_2012}\relax }}{37}{figure.caption.35}%
\contentsline {figure}{\numberline {III.22}{\ignorespaces Grafico di $k(x,x')$ squared-exponential kernel sommato a periodic kernel. $\sigma ^2=1$, $l=2$, $p=1$. Codice \ref {RBF + periodic kernel}.\relax }}{39}{figure.caption.37}%
\contentsline {figure}{\numberline {III.23}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è lo squared-exponential sommato al periodic kernel e $l^2=1.1$, $\sigma ^2=1$, $p=1.1$. Codice \ref {RBF + periodic sample}.\relax }}{39}{figure.caption.38}%
\contentsline {figure}{\numberline {III.24}{\ignorespaces Grafico di $k(x,x')$ linear kernel moltiplicato a linear kernel. $\sigma _b^2=0$, $\sigma _v^2=1$, $c=0$, $x'=1$. Codice \ref {linear x linear}.\relax }}{40}{figure.caption.40}%
\contentsline {figure}{\numberline {III.25}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(x,x')$ è il linear kernel moltiplicato al linear kernel e $\sigma _b^2=0$, $\sigma _v^2=1$, $c=0$. Codice \ref {linear x linear sample}.\relax }}{40}{figure.caption.41}%
\contentsline {figure}{\numberline {III.26}{\ignorespaces 545 osservazioni delle medie mensili della concentrazione atmosferica di $CO_2$ tra il 1958 e il 2003, inoltre viene mostrata la regione di confidenza del $95\%$ per un modello di regressione di processo gaussiano a 20 anni nel futuro. \blx@tocontentsinit {0}\cite {rasmussen_gaussian_2006}\relax }}{41}{figure.caption.43}%
\contentsline {figure}{\numberline {III.27}{\ignorespaces Comparazione della predizione della concentrazione di $CO_2$ con i dati reali fino a maggio 2022.\relax }}{42}{figure.caption.44}%
\contentsline {figure}{\numberline {III.28}{\ignorespaces Comparazione della predizione della concentrazione di $CO_2$ con i dati reali fino dal 1995 a maggio 2022.\relax }}{43}{figure.caption.45}%
\contentsline {figure}{\numberline {III.29}{\ignorespaces Spiegazione grafica di come viene incorporata la conoscenza a priori \blx@tocontentsinit {0}\cite {gortler_visual_2019}.\relax }}{44}{figure.caption.46}%
\contentsline {figure}{\numberline {III.30}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(\cdot ,\cdot )$ è il squared-exponential kernel; il processo gaussiano è stato condizionato per interpolare sei punti. Viene mostrata in rosso la funzione da cui sono stati scelti i punti da interpolare, in blu la media del processo gaussiano condizionato, come linee tratteggiate alcuni sample del processo gaussiano. Codice \ref {interpolation code}.\relax }}{46}{figure.caption.47}%
\contentsline {figure}{\numberline {III.31}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(\cdot ,\cdot )$ è il squared-exponential kernel; il processo gaussiano è stato condizionato per interpolare sei punti. Viene mostrata in blu la regione di confidenza al 95\%, in blu la media del processo gaussiano condizionato e come linee tratteggiate alcuni sample. Codice \ref {interpolation confidence region code}.\relax }}{47}{figure.caption.48}%
\contentsline {figure}{\numberline {III.32}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(\cdot ,\cdot )$ è il squared-exponential kernel; il processo gaussiano è stato condizionato per predire una funzione a partire dalle sue osservazioni rumorose. Viene mostrata in rosso la funzione da predire, in rosso i punti osservati della funzione con le barre rappresentanti il rumore, in blu la media del processo gaussiano condizionato, come linee tratteggiate alcuni sample del processo gaussiano. Codice \ref {Noise code}.\relax }}{48}{figure.caption.49}%
\contentsline {figure}{\numberline {III.33}{\ignorespaces Grafico di funzioni con distribuzione $f\sim \mathcal {GP}(\bm {0},k)$ dove $k(\cdot ,\cdot )$ è il squared-exponential kernel; il processo gaussiano è stato condizionato per predire una funzione a partire dalle sue osservazioni rumorose. Viene mostrata in blu la regione di confidenza al 95\%, in rosso con le barre di errore le osservazioni, in blu la media del processo gaussiano condizionato e come linee tratteggiate alcuni sample. Codice \ref {Noise confidence region code}.\relax }}{49}{figure.caption.50}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {IV.1}{\ignorespaces Esempio di overfitting. I dati (approssimativamente lineari) sono approssimati da una funzione lineare e da una polinomiale. Anche se la funzione polinomiale fornisce un adattamento quasi perfetto, ci si può aspettare che la funzione lineare generalizzi meglio i dati. \blx@tocontentsinit {0}\cite {wiki:overfitting}\relax }}{53}{figure.caption.51}%
\contentsline {figure}{\numberline {IV.2}{\ignorespaces Overfitting nell'apprendimento supervisionato. Il training error (errore sul training set) è mostrato in blu, il validation error (errore su validation set) in rosso, entrambi in funzione del numero di cicli di training. \blx@tocontentsinit {0}\cite {wiki:overfitting}\relax }}{54}{figure.caption.52}%
\contentsline {figure}{\numberline {IV.3}{\ignorespaces Illustrazione del metodo del gradiente su degli insiemi di livello, ad ogni iterazione viene aggiornato il learning rate.\blx@tocontentsinit {0}\cite {wiki:gradientDescend}\relax }}{63}{figure.caption.53}%
\contentsline {figure}{\numberline {IV.4}{\ignorespaces Metodo dei momenti applicato al metodo stocastico del gradiente. \blx@tocontentsinit {0}\cite {ruder_2022}\relax }}{65}{figure.caption.54}%
\contentsline {figure}{\numberline {IV.5}{\ignorespaces Comparazione di metodi di minimizzazione di una cost function in una rete neurale. \blx@tocontentsinit {0}\cite {kingma_adam_2017}\relax }}{68}{figure.caption.55}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {V.1}{\ignorespaces Pressione sistemica e flusso aortico misurati in un paziente. Codice \ref {datiReali}.\relax }}{70}{figure.caption.56}%
\contentsline {figure}{\numberline {V.2}{\ignorespaces Grafico della pressione reale e output del modello semplice. Codice \ref {modelloSemplice}.\relax }}{71}{figure.caption.57}%
\contentsline {figure}{\numberline {V.3}{\ignorespaces Anatomia del cuore umano \blx@tocontentsinit {0}\cite {wiki:cicloCardiaco}.\relax }}{72}{figure.caption.58}%
\contentsline {figure}{\numberline {V.4}{\ignorespaces Diagrammi che riassumono la sistole e la diastole di un cuore umano \blx@tocontentsinit {0}\cite {wiki:cicloCardiaco}.\relax }}{73}{figure.caption.59}%
\contentsline {figure}{\numberline {V.5}{\ignorespaces Esempio di diagramma di Wiggers \blx@tocontentsinit {0}\cite {wiki:DiagrammaWiggers}.\relax }}{75}{figure.caption.61}%
\contentsline {figure}{\numberline {V.6}{\ignorespaces Illustrazione dell'analogia sull'effetto windkessel \blx@tocontentsinit {0}\cite {wiki:WindkesselEffect}.\relax }}{77}{figure.caption.66}%
\contentsline {figure}{\numberline {V.7}{\ignorespaces Illustrazione dell'effetto windkessel \blx@tocontentsinit {0}\cite {AaronsonPhilipI.PhilipIrving2020Tcsa}.\relax }}{78}{figure.caption.67}%
\contentsline {figure}{\numberline {V.8}{\ignorespaces Forma circuitale del modello Windkessel a due elementi.\relax }}{81}{figure.caption.68}%
\contentsline {figure}{\numberline {V.9}{\ignorespaces Grafico di $f_C$. Codice \ref {plotfC-code}.\relax }}{82}{figure.caption.69}%
\contentsline {figure}{\numberline {V.10}{\ignorespaces Grafico della soluzione approssimata dell'equazione (\ref {equation}) con $C$ stimata. Codice \ref {plotSoluzioneCstimata}.\relax }}{82}{figure.caption.70}%
\contentsline {figure}{\numberline {V.11}{\ignorespaces Grafico della soluzione approssimata dell'equazione (\ref {equation}) con $C=2,11579mL/mmHg$ e $\alpha =0,97134$. Codice \ref {soluzioneCalphastimate}.\relax }}{83}{figure.caption.71}%
\contentsline {figure}{\numberline {V.12}{\ignorespaces Grafico della soluzione dell'equazione (\ref {equation}) approssimata dopo venti cicli cardiaci con $C=2,03424mL/mmHg$ e $\alpha =0,97354$.\relax }}{85}{figure.caption.72}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {VI.1}{\ignorespaces Distribuzione dei dati nel database.\relax }}{94}{figure.caption.77}%
\contentsline {figure}{\numberline {VI.2}{\ignorespaces MAP: andamento del training e validation loss, early stopper, R2Score e MSE.\relax }}{95}{figure.caption.79}%
\contentsline {figure}{\numberline {VI.3}{\ignorespaces MAP: predizioni sui dati di input.\relax }}{96}{figure.caption.81}%
\contentsline {figure}{\numberline {VI.4}{\ignorespaces Dipendenza di MAP da $C$ sull'intervallo di training e due intervalli attigui.\relax }}{97}{figure.caption.83}%
\contentsline {figure}{\numberline {VI.5}{\ignorespaces Dipendenza di MAP da $C$ sull'intervallo di training.\relax }}{97}{figure.caption.84}%
\contentsline {figure}{\numberline {VI.6}{\ignorespaces Dipendenza di MAP da $C$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{98}{figure.caption.85}%
\contentsline {figure}{\numberline {VI.7}{\ignorespaces Dipendenza di MAP da $C$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{98}{figure.caption.86}%
\contentsline {figure}{\numberline {VI.8}{\ignorespaces Dipendenza di MAP da $R1$ sull'intervallo di training e due intervalli attigui.\relax }}{99}{figure.caption.88}%
\contentsline {figure}{\numberline {VI.9}{\ignorespaces Dipendenza di MAP da $R1$ sull'intervallo di training.\relax }}{99}{figure.caption.89}%
\contentsline {figure}{\numberline {VI.10}{\ignorespaces Dipendenza di MAP da $R1$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{100}{figure.caption.90}%
\contentsline {figure}{\numberline {VI.11}{\ignorespaces Dipendenza di MAP da $R1$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{100}{figure.caption.91}%
\contentsline {figure}{\numberline {VI.12}{\ignorespaces Dipendenza di MAP da $R2$ sull'intervallo di training e due intervalli attigui.\relax }}{101}{figure.caption.93}%
\contentsline {figure}{\numberline {VI.13}{\ignorespaces Dipendenza di MAP da $R2$ sull'intervallo di training.\relax }}{101}{figure.caption.94}%
\contentsline {figure}{\numberline {VI.14}{\ignorespaces Dipendenza di MAP da $R2$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{102}{figure.caption.95}%
\contentsline {figure}{\numberline {VI.15}{\ignorespaces Dipendenza di MAP da $R2$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{102}{figure.caption.96}%
\contentsline {figure}{\numberline {VI.16}{\ignorespaces DBP: andamento del training e validation loss, early stopper, R2Score e MSE.\relax }}{103}{figure.caption.98}%
\contentsline {figure}{\numberline {VI.17}{\ignorespaces DBP: predizioni sui dati di input.\relax }}{103}{figure.caption.100}%
\contentsline {figure}{\numberline {VI.18}{\ignorespaces Dipendenza di DBP da $C$ sull'intervallo di training e due intervalli attigui.\relax }}{104}{figure.caption.102}%
\contentsline {figure}{\numberline {VI.19}{\ignorespaces Dipendenza di DBP da $C$ sull'intervallo di training.\relax }}{104}{figure.caption.103}%
\contentsline {figure}{\numberline {VI.20}{\ignorespaces Dipendenza di DBP da $C$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{105}{figure.caption.104}%
\contentsline {figure}{\numberline {VI.21}{\ignorespaces Dipendenza di DBP da $C$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{105}{figure.caption.105}%
\contentsline {figure}{\numberline {VI.22}{\ignorespaces Dipendenza di DBP da $R_1$ sull'intervallo di training e due intervalli attigui.\relax }}{106}{figure.caption.107}%
\contentsline {figure}{\numberline {VI.23}{\ignorespaces Dipendenza di DBP da $R_1$ sull'intervallo di training.\relax }}{106}{figure.caption.108}%
\contentsline {figure}{\numberline {VI.24}{\ignorespaces Dipendenza di DBP da $R_1$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{107}{figure.caption.109}%
\contentsline {figure}{\numberline {VI.25}{\ignorespaces Dipendenza di DBP da $R_1$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{107}{figure.caption.110}%
\contentsline {figure}{\numberline {VI.26}{\ignorespaces Dipendenza di DBP da $R_2$ sull'intervallo di training e due intervalli attigui.\relax }}{108}{figure.caption.112}%
\contentsline {figure}{\numberline {VI.27}{\ignorespaces Dipendenza di DBP da $R_2$ sull'intervallo di training.\relax }}{108}{figure.caption.113}%
\contentsline {figure}{\numberline {VI.28}{\ignorespaces Dipendenza di DBP da $R_2$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{109}{figure.caption.114}%
\contentsline {figure}{\numberline {VI.29}{\ignorespaces Dipendenza di DBP da $R_2$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{109}{figure.caption.115}%
\contentsline {figure}{\numberline {VI.30}{\ignorespaces PP: andamento del training e validation loss, early stopper, R2Score e MSE.\relax }}{110}{figure.caption.117}%
\contentsline {figure}{\numberline {VI.31}{\ignorespaces PP: predizioni sui dati di input.\relax }}{110}{figure.caption.119}%
\contentsline {figure}{\numberline {VI.32}{\ignorespaces Dipendenza di PP da $C$ sull'intervallo di training e due intervalli attigui.\relax }}{111}{figure.caption.121}%
\contentsline {figure}{\numberline {VI.33}{\ignorespaces Dipendenza di PP da $C$ sull'intervallo di training.\relax }}{111}{figure.caption.122}%
\contentsline {figure}{\numberline {VI.34}{\ignorespaces Dipendenza di PP da $C$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{112}{figure.caption.123}%
\contentsline {figure}{\numberline {VI.35}{\ignorespaces Dipendenza di PP da $C$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{112}{figure.caption.124}%
\contentsline {figure}{\numberline {VI.36}{\ignorespaces Dipendenza di PP da $R1$ sull'intervallo di training e due intervalli attigui.\relax }}{113}{figure.caption.126}%
\contentsline {figure}{\numberline {VI.37}{\ignorespaces Dipendenza di PP da $R1$ sull'intervallo di training.\relax }}{113}{figure.caption.127}%
\contentsline {figure}{\numberline {VI.38}{\ignorespaces Dipendenza di PP da $R1$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{114}{figure.caption.128}%
\contentsline {figure}{\numberline {VI.39}{\ignorespaces Dipendenza di PP da $R1$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{114}{figure.caption.129}%
\contentsline {figure}{\numberline {VI.40}{\ignorespaces Dipendenza di PP da $R2$ sull'intervallo di training e due intervalli attigui.\relax }}{115}{figure.caption.131}%
\contentsline {figure}{\numberline {VI.41}{\ignorespaces Dipendenza di PP da $R2$ sull'intervallo di training.\relax }}{115}{figure.caption.132}%
\contentsline {figure}{\numberline {VI.42}{\ignorespaces Dipendenza di PP da $R2$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{116}{figure.caption.133}%
\contentsline {figure}{\numberline {VI.43}{\ignorespaces Dipendenza di PP da $R2$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{116}{figure.caption.134}%
\contentsline {figure}{\numberline {VI.44}{\ignorespaces SBP: andamento del training e validation loss, early stopper, R2Score e MSE.\relax }}{117}{figure.caption.136}%
\contentsline {figure}{\numberline {VI.45}{\ignorespaces SBP: predizioni sui dati di input.\relax }}{117}{figure.caption.138}%
\contentsline {figure}{\numberline {VI.46}{\ignorespaces Dipendenza di SBP da $C$ sull'intervallo di training e due intervalli attigui.\relax }}{118}{figure.caption.140}%
\contentsline {figure}{\numberline {VI.47}{\ignorespaces Dipendenza di SBP da $C$ sull'intervallo di training.\relax }}{118}{figure.caption.141}%
\contentsline {figure}{\numberline {VI.48}{\ignorespaces Dipendenza di SBP da $C$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{119}{figure.caption.142}%
\contentsline {figure}{\numberline {VI.49}{\ignorespaces Dipendenza di SBP da $C$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{119}{figure.caption.143}%
\contentsline {figure}{\numberline {VI.50}{\ignorespaces Dipendenza di SBP da $R1$ sull'intervallo di training e due intervalli attigui.\relax }}{120}{figure.caption.145}%
\contentsline {figure}{\numberline {VI.51}{\ignorespaces Dipendenza di SBP da $R1$ sull'intervallo di training.\relax }}{120}{figure.caption.146}%
\contentsline {figure}{\numberline {VI.52}{\ignorespaces Dipendenza di SBP da $R1$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{121}{figure.caption.147}%
\contentsline {figure}{\numberline {VI.53}{\ignorespaces Dipendenza di SBP da $R1$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{121}{figure.caption.148}%
\contentsline {figure}{\numberline {VI.54}{\ignorespaces Dipendenza di SBP da $R2$ sull'intervallo di training e due intervalli attigui.\relax }}{122}{figure.caption.150}%
\contentsline {figure}{\numberline {VI.55}{\ignorespaces Dipendenza di SBP da $R2$ sull'intervallo di training.\relax }}{122}{figure.caption.151}%
\contentsline {figure}{\numberline {VI.56}{\ignorespaces Dipendenza di SBP da $R2$ sull'intervallo attiguo a sinistra dell'intervallo di training.\relax }}{123}{figure.caption.152}%
\contentsline {figure}{\numberline {VI.57}{\ignorespaces Dipendenza di SBP da $R2$ sull'intervallo attiguo a destra dell'intervallo di training.\relax }}{123}{figure.caption.153}%
\addvspace {10\p@ }
